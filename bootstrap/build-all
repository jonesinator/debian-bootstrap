#!/bin/sh
set -eu

# Debian mirror configuration.
: "${debian_mirror_url:="http://deb.debian.org/debian"}"
: "${debian_mirror_distribution:="bookworm"}"
: "${debian_mirror_components:="main"}"
: "${debian_mirror_key_url:="https://ftp-master.debian.org/keys"}"
: "${debian_mirror_keys:="archive-key-11.asc archive-key-12.asc release-12.asc"}"
: "${debian_mirror_fingerprints:="1F89983E0081FDE018F3CC9673A4F27B8DD47936"
                                 "B8B80B5B623EAB6AD8775C45B7C5D7D6350947F8"
                                 "4D64FEC119C2029067D6E791F8D2585B8783D481"}"

# Verification configuration.
: "${keyserver:="hkps://keyserver.ubuntu.com"}"

# Local directory configuration.
: "${cache_dir:="./cache"}"
: "${temp_dir:="./tmp"}"
: "${output_dir:="./rootfs"}"

#
# Functions
#

# Executes a command in a target directory as the root directory.
in_target() {
    env -i PATH="/usr/bin:/usr/sbin" DEBIAN_FRONTEND=noninteractive chroot "${@}"
}

# Takes two lists as arguments, and removes any line in the second from the
# first. The result is output on stdout.
remove_from() {
    printf "%s\n%s\n%s" "${1}" "${2}" "${2}" | sort | uniq -u
}

# Determines the path in the local cache to a file by its URL. Prints the path
# to the file on stdout.
cache_path() {
    url__a="${1}"
    cache_dir__a="${2}"

    host__a="$(echo "${url__a}" | sed 's|^https\?://||' | cut -d/ -f1)"
    file_path__a="$(echo "${url__a}" | sed 's|^https\?://||' | cut -d/ -f2-)"
    echo "${cache_dir__a}/${host__a}/${file_path__a}" |
        sed 's/%/\\\\x/g' | xargs echo -e

    unset url__a cache_dir__a host__a file_path__a
}

# Downloads a file by URL to the local cache and prints the path to the file on
# stdout. Any existing file will not be overwritten, and if the file exists then
# this function will not attempt to reach out to the internet. This function
# should be safe to use in offline contexts assuming the cache is populated.
#
# ALL access to the internet should be mediated through this function, and this
# function alone.
download() {
    url__b="${1}"
    cache_dir__b="${2}"

    wget -nc "${url__b}" \
        -P "$(dirname "$(cache_path "${url__b}" "${cache_dir__b}")")"
    cache_path "${url__b}" "${cache_dir__b}"

    unset url__b cache_dir__b
}

# Prints the contents of the "InRelease" file of the package archive after
# validating its signatures. The contents of the signed "InRelease" file and the
# public keys used to validate it are cached in the cache directory.
get_release() {
    mirror__c="${1}"
    distribution__c="${2}"
    key_url__c="${3}"
    keys__c="${4}"
    fingerprints__c="${5}"
    keyserver__c="${6}"
    cache_dir__c="${7}"
    temp_path__c="${8}"

    # Download the signing keys and the InRelease file, then validate the
    # InRelease file.
    rm -rf "${temp_path__c}"
    mkdir -m 0700 "${temp_path__c}"
    for key__c in ${keys__c}; do
        key_path__c="$(download "${key_url__c}/${key__c}" "${cache_dir__c}")"
        gpg --homedir "${temp_path__c}" --import "${key_path__c}"
    done
    in_release_path__c="$(download \
        "${mirror__c}/dists/${distribution__c}/InRelease" "${cache_dir__c}")"
    gpg --homedir "${temp_path__c}" --verify "${in_release_path__c}"
    rm -rf "${temp_path__c}"

    # Validate the InRelease file using the fingerprints and a keyserver, if
    # requested.
    if [ "${keyserver__c}" != "none" ]; then
        mkdir -m 0700 "${temp_path__c}"
        for fingerprint__c in ${fingerprints__c}; do
            gpg --homedir "${temp_path__c}" \
                --keyserver "${keyserver__c}" \
                --recv-keys "${fingerprint__c}"
        done
        gpg --homedir "${temp_path__c}" --verify "${in_release_path__c}"
        rm -rf "${temp_path__c}"
    fi

    cat "${in_release_path__c}"

    unset mirror__c distribution__c key_url__c keys__c fingerprints__c
    unset keyserver__c cache_dir__c temp_path__c key__c in_release_path__c
    unset fingerprint__c
}

# Prints the verified contents a file described by the "Release" file of the
# package archive by path.
get_release_file() {
    mirror__d="${1}"
    distribution__d="${2}"
    release__d="${3}"
    path__d="${4}"
    cache_dir__d="${5}"
    temp_path__d="${6}"

    # Parse the files from the release in the format " {sha256} {size} {path}".
    # The first sed starts capturing after the line with "SHA256:", and the
    # second sed stops capturing on the first line that does not stop with a
    # space.
    files__d="$(echo "${release__d}" | sed '1,/^SHA256:$/ d' | sed '/^[^ ]/Q')"

    # Look for the compressed file.
    for compression__d in "xz" "gz"; do
        packed_path__d="${path__d}.${compression__d}"
        packed_hash__d="$(echo "${files__d}" |
            grep " ${packed_path__d}$" | cut -d' ' -f2)"
        if [ -n "${packed_hash__d}" ]; then
            break
        fi
    done
    if [ -z "${packed_hash__d}" ]; then
        return 1
    fi

    # Prefer getting files by their hash if possible.
    by_hash__d="$( \
        echo "${release__d}" | sed -n 's/Acquire-By-Hash: //p' || echo "no")"
    if [ "${by_hash__d}" = "yes" ]; then
        download_path__d="$(dirname "${path__d}")/by-hash/SHA256/${packed_hash__d}"
    else
        download_path__d="${packed_path__d}"
    fi

    # Get the compressed file and check its hash.
    url__d="${mirror__d}/dists/${distribution__d}/${download_path__d}"
    file__d="$(download "${url__d}" "${cache_dir__d}")"
    echo "${packed_hash__d}  ${file__d}" | sha256sum -c --status

    # Decompress the downloaded file and check its hash as well.
    extension__d="$(echo "${packed_path__d}" | rev | cut -d. -f1 | rev)"
    rm -rf "${temp_path__d}"
    case "${extension__d}" in
        gz) gzip --decompress --stdout "${file__d}" > "${temp_path__d}" ;;
        xz) xz --decompress --stdout "${file__d}" > "${temp_path__d}" ;;
    esac
    unpacked_hash__d="$(echo "${files__d}" | grep "${path__d}$" | cut -d' ' -f2)"
    echo "${unpacked_hash__d}  ${temp_path__d}" | sha256sum -c --status
    cat "${temp_path__d}"
    rm "${temp_path__d}"

    unset mirror__d distribution__d release__d path__d cache_dir__d temp_path__d
    unset files__d compression__d packed_path__d packed_hash__d by_hash__d
    unset download_path__d url__d file__d extension__d unpacked_hash__d
}

# Converts a package metadata file URL to the filename it should have in
# /var/cache/apt. Prints the filename to stdout.
url_to_apt_list() {
    url__e="${1}"

    echo "${url__e}" | sed 's|^https\?://||' | sed 's|/|_|g'

    unset url__e
}

# Runs a "manual" apt update by downloading the appropriate package metadata
# files from the mirror and putting them in the output dir with the correct
# names for /var/cache/apt. Effectially this does an "apt update", but it uses
# this script's cache and download utilities.
manual_apt_update() {
    url__f="${1}"
    distribution__f="${2}"
    components__f="${3}"
    key_url__f="${4}"
    keys__f="${5}"
    fingerprints__f="${6}"
    keyserver__f="${7}"
    cache_dir__f="${8}"
    temp_dir__f="${9}"
    out_dir__f="${10}"
    shift 10
    files__f="${*}"

    prefix__f="${url__f}/dists/${distribution__f}"
    release_data__f="$(get_release \
        "${url__f}" \
        "${distribution__f}" \
        "${key_url__f}" \
        "${keys__f}" \
        "${fingerprints__f}" \
        "${keyserver__f}" \
        "${cache_dir__f}" \
        "${temp_dir__f}" | tee "${out_dir__f}/$(url_to_apt_list "${prefix__f}/InRelease")")"
    for component__f in ${components__f}; do
        for file__f in ${files__f}; do
            contents__f="$(get_release_file \
                "${url__f}" \
                "${distribution__f}" \
                "${release_data__f}" \
                "${component__f}/${file__f}" \
                "${cache_dir__f}" \
                "${temp_dir__f}")"
            if [ -n "${contents__f}" ]; then
                echo "${contents__f}" > "${out_dir__f}/$(url_to_apt_list "${prefix__f}/${component__f}/${file__f}")"
            fi
        done
    done

    touch "${out_dir__f}/lock"
    mkdir -p "${out_dir__f}/auxfiles"
    mkdir -p "${out_dir__f}/partial"

    unset url__f distribution__f components__f key_url__f keys__f
    unset fingerprints__f keyserver__f cache_dir__f temp_dir__f out_dir__f
    unset files__f prefix__f release_data__f component__f file__f contents__f
}

manual_apt_install() {
    cache_dir__g="${1}"
    output_dir__g="${2}"
    save_path__g="${3}"
    command__g="${4}"
    shift 4
    args__g="${*}"

    # shellcheck disable=SC2086
    infos__g="$(in_target "${output_dir__g}" apt-get -qq "${command__g}" --print-uris ${args__g})"
    echo "${infos__g}" | while IFS= read -r info__g; do
      uri__g="$(echo "${info__g}" | cut -d' ' -f1 | tr -d "\'")"
      destination__g="$(echo "${info__g}" | cut -d' ' -f2)"
      hash__g="$(echo "${info__g}" | cut -d' ' -f4)"
      cache_path__g="$(download "${uri__g}" "${cache_dir__g}")"
      if [ -n "${hash__g}" ]; then
	  algorithm__g="$(echo "${hash__g}" | cut -f1 -d:)"
	  hash_value__g="$(echo "${hash__g}" | cut -f2 -d:)"
	  case "${algorithm__g}" in
            MD5Sum) echo "${hash_value__g}  ${cache_path__g}" | md5sum -c --status ;;
            SHA256) echo "${hash_value__g}  ${cache_path__g}" | sha256sum -c --status ;;
	  esac
      else
          echo "WARNING: Not validating hash for ${destination__g}" 1>&2
      fi
      mkdir -p "${output_dir__g}/${save_path__g}"
      cp "${cache_path__g}" "${output_dir__g}/${save_path__g}/${destination__g}"
    done
    set -x
    # shellcheck disable=SC2086
    in_target "${output_dir__g}" sh -c "cd /${save_path__g} && apt-get ${command__g} --no-download --yes ${args__g}"
    set +x

    unset cache_dir__g output_dir__g command__g args__g infos__g uri__g
    unset destination__g md5_hash__g cache_path__g
}

mount_all() {
    mkdir -p "${output_dir}/tmp"
    mount -t tmpfs nodev "${output_dir}/tmp"
    mount -t proc nodev "${output_dir}/proc"
    mount -t devtmpfs nodev "${output_dir}/dev"
    mkdir -p "${output_dir}/cache"
    mount --bind "${cache_dir}" "${output_dir}/cache"
}

unmount_all() {
    umount "${output_dir}/tmp" || true
    umount "${output_dir}/dev" || true
    umount "${output_dir}/proc" || true
    umount "${output_dir}/cache" || true
}

#
# Main Script
#

rm -rf debs
mkdir debs
for package in $(cat all-packages | tr "\n" " "); do
    unmount_all
    cp -r "${output_dir}" "${output_dir}.bak"
    mount_all

    manual_apt_install "${cache_dir}" "${output_dir}" /var/cache/apt/archives build-dep "${package}"
    manual_apt_install "${cache_dir}" "${output_dir}" /build source "${package}"
    in_target "${output_dir}" sh -c 'cd "$(find /build -maxdepth 1 -mindepth 1 -type d)" && DEB_BUILD_OPTIONS=nocheck dpkg-buildpackage -us -uc'
    mv "${output_dir}/build/"*.deb debs

    unmount_all
    rm -rf "${output_dir}"
    mv "${output_dir}.bak" "${output_dir}"
done
